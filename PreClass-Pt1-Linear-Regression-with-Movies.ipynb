{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7b8cd1",
   "metadata": {},
   "source": [
    "# Linear Regression with Statsmodels for Movie Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be646c03",
   "metadata": {},
   "source": [
    "- xx/xx/xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550a29d",
   "metadata": {},
   "source": [
    "## Activity: Create a Linear Regression Model with Statsmodels for Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906f994",
   "metadata": {},
   "source": [
    "- Today we will be working with JUST the data data from the TMDB API for years 2000-2021. \n",
    "    - We will prepare the data for modeling\n",
    "        - Some feature engineering\n",
    "        - Our usual Preprocessing\n",
    "        - New steps for statsmodels!\n",
    "    - We will fit a statsmodels linear regression.\n",
    "    - We Will inspect the model summary.\n",
    "    - We will create the visualizations to check assumptions about the residuals.\n",
    "\n",
    "\n",
    "\n",
    "- Next class we will continue this activity.\n",
    "    - We will better check all 4 assumptions.\n",
    "    - We will discuss tactics for dealing with violations of the assumptions. \n",
    "    - We will use our coefficients to make stakeholder recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053aec11",
   "metadata": {},
   "source": [
    "### Concepts Demonstrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd3fb6",
   "metadata": {},
   "source": [
    "- [ ] Using `glob` for loading in all final files. \n",
    "- [ ] Statsmodels OLS\n",
    "- [ ] QQ-Plot\n",
    "- [ ] Residual Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd0241",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e05555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "## fixing random for lesson generation\n",
    "np.random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b603a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad0a31",
   "metadata": {},
   "source": [
    "### ðŸ“š Finding & Loading Batches of Files with `glob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff0331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2010-2021',\n",
       " 'combined_tmdb_data.csv.gz',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'final_tmdb_data_2002.csv.gz',\n",
       " 'final_tmdb_data_2003.csv.gz',\n",
       " 'final_tmdb_data_2004.csv.gz',\n",
       " 'final_tmdb_data_2005.csv.gz',\n",
       " 'final_tmdb_data_2006.csv.gz',\n",
       " 'final_tmdb_data_2007.csv.gz',\n",
       " 'final_tmdb_data_2008.csv.gz',\n",
       " 'final_tmdb_data_2009.csv.gz',\n",
       " 'title_akas_cleaned.csv.gz',\n",
       " 'title_basics_cleaned.csv.gz',\n",
       " 'title_ratings_cleaned.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_api_results_2002.json',\n",
       " 'tmdb_api_results_2003.json',\n",
       " 'tmdb_api_results_2004.json',\n",
       " 'tmdb_api_results_2005.json',\n",
       " 'tmdb_api_results_2006.json',\n",
       " 'tmdb_api_results_2007.json',\n",
       " 'tmdb_api_results_2008.json',\n",
       " 'tmdb_api_results_2009.json',\n",
       " 'tmdb_api_results_2010.json',\n",
       " 'tmdb_api_results_2011.json',\n",
       " 'tmdb_api_results_2012.json',\n",
       " 'tmdb_api_results_2013.json',\n",
       " 'tmdb_api_results_2014.json',\n",
       " 'tmdb_api_results_2015.json',\n",
       " 'tmdb_api_results_2016.json',\n",
       " 'tmdb_api_results_2017.json',\n",
       " 'tmdb_api_results_2018.json',\n",
       " 'tmdb_api_results_2019.json',\n",
       " 'tmdb_api_results_2020.json',\n",
       " 'tmdb_api_results_2021.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking what data we already have in our Data folder using os.listdir\n",
    "import os\n",
    "FOLDER = 'Data/'\n",
    "file_list = sorted(os.listdir(FOLDER))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b13c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_tmdb_data_2001.csv.gz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Try loading in the first .csv.gz file from the list\n",
    "file_list[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e4c80",
   "metadata": {},
   "source": [
    "> Why isn't it working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e08745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's check the filepath \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02f97f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/final_tmdb_data_2001.csv.gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add the folder plus filename\n",
    "FOLDER + file_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d88d81ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/FOLDER'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## try read csv with folder plus filename\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/FOLDER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/FOLDER'"
     ]
    }
   ],
   "source": [
    "## try read csv with folder plus filename\n",
    "pd.read_csv('Data/FOLDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce0f60",
   "metadata": {},
   "source": [
    "- Now we would do that in a loop, and only want to open .csv.gz.\n",
    "- But there is a better way!\n",
    ">- Introducing `glob`\n",
    "    - Glob takes a filepath/query and will find every filename that matches the pattern provided.\n",
    "    - We use asterisks as wildcards in our query.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5240524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/*.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "## Make a filepath query\n",
    "q = FOLDER + '*.csv.gz'\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cec2290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/final_tmdb_data_2006.csv.gz',\n",
       " 'Data/title_basics_cleaned.csv.gz',\n",
       " 'Data/final_tmdb_data_2008.csv.gz',\n",
       " 'Data/final_tmdb_data_2004.csv.gz',\n",
       " 'Data/title_ratings_cleaned.csv.gz',\n",
       " 'Data/final_tmdb_data_2000.csv.gz',\n",
       " 'Data/final_tmdb_data_2002.csv.gz',\n",
       " 'Data/combined_tmdb_data.csv.gz',\n",
       " 'Data/final_tmdb_data_2007.csv.gz',\n",
       " 'Data/final_tmdb_data_2009.csv.gz',\n",
       " 'Data/final_tmdb_data_2005.csv.gz',\n",
       " 'Data/final_tmdb_data_2001.csv.gz',\n",
       " 'Data/title_akas_cleaned.csv.gz',\n",
       " 'Data/final_tmdb_data_2003.csv.gz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use glob.glob to get COMPLETE filepaths\n",
    "file_list = glob.glob(q)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af6a0c",
   "metadata": {},
   "source": [
    "> But where are the rest of the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8396d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/final_*.csv.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/final_tmdb_data_2000.csv.gz',\n",
       " 'Data/final_tmdb_data_2001.csv.gz',\n",
       " 'Data/final_tmdb_data_2002.csv.gz',\n",
       " 'Data/final_tmdb_data_2003.csv.gz',\n",
       " 'Data/final_tmdb_data_2004.csv.gz',\n",
       " 'Data/final_tmdb_data_2005.csv.gz',\n",
       " 'Data/final_tmdb_data_2006.csv.gz',\n",
       " 'Data/final_tmdb_data_2007.csv.gz',\n",
       " 'Data/final_tmdb_data_2008.csv.gz',\n",
       " 'Data/final_tmdb_data_2009.csv.gz']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in a sub-folder\n",
    "q = FOLDER + 'final_*.csv.gz'\n",
    "print(q)\n",
    "file_list = sorted(glob.glob(q))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1059279b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_tmdb_data_2010.csv.gz',\n",
       " 'final_tmdb_data_2011.csv.gz',\n",
       " 'final_tmdb_data_2012.csv.gz',\n",
       " 'final_tmdb_data_2013.csv.gz',\n",
       " 'final_tmdb_data_2014.csv.gz',\n",
       " 'final_tmdb_data_2015.csv.gz',\n",
       " 'final_tmdb_data_2016.csv.gz',\n",
       " 'final_tmdb_data_2017.csv.gz',\n",
       " 'final_tmdb_data_2018.csv.gz',\n",
       " 'final_tmdb_data_2019.csv.gz',\n",
       " 'final_tmdb_data_2020.csv.gz',\n",
       " 'final_tmdb_data_2021.csv.gz']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(FOLDER+'2010-2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3f096",
   "metadata": {},
   "source": [
    "- Recursive Searching with glob.\n",
    "    - add a `**/` in the middle of your query to grab any matches from all subfolders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c6c8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data//**/final_*.csv_gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use glob.glob to get COMPLETE filepaths\n",
    "q = FOLDER+'/**/final_*.csv_gz'\n",
    "print(q)\n",
    "file_list = sorted(glob.glob(q, recursive=True))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33076ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use a list comprehension to load in all files into 1 dataframe\n",
    "pd.concat([pd.read_csv(f) for f in file_list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbcbd5",
   "metadata": {},
   "source": [
    "- Dealing with ParserErrors with \"possibly malformed files\"\n",
    "\n",
    "    - for a reason I do not fully understand yet, some of the files I downloaded error if I try to read them.\n",
    "        - \"ParserError: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.`\n",
    "    - After some googling, the fix was to add `lineterminator='\\n'` to pd.read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d951889",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# remove ids that are 0  and then reset index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove ids that are 0  and then reset index\n",
    "df = df.loc[df['imdb_id'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767099fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faffae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the combined csv to disk\n",
    "df.to_csv(FOLDER+'combined_dmdb_data.csv.gz', compress='gzip', lineterminator='\\n')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635b936",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd187327",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a013019",
   "metadata": {},
   "source": [
    "- belongs to collection: convert to boolean\n",
    "- Genres: get just name and manually OHE\n",
    "- Cleaning Categories in Certification\n",
    "- Converting release date to year, month, and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a37e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcdcc8bc",
   "metadata": {},
   "source": [
    "### belongs to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266c94ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# there are 3,700+ movies that belong to collections\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbelongs_to_collection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# there are 3,700+ movies that belong to collections\n",
    "df['belongs_to_collection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbc083",
   "metadata": {},
   "source": [
    "### genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80aa21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get just the genre names as a list \n",
    "import json\n",
    "def get_genre_name(x):\n",
    "    x = x.replace(\"'\",'\"')\n",
    "    x = json.loads(x)\n",
    "    \n",
    "    genres = []\n",
    "    for genre in x:\n",
    "        genres.append(genre['name'])\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use our function and exploding the new column\n",
    "#get_genre_name(df.loc[3,'genres'])\n",
    "\n",
    "# use get_genre_name and convert all the genere name in list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save unique genres\n",
    "\n",
    "unique_genres = df_explode['genre_list'].dropna().unique()\n",
    "unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a800f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually One-Hot-Encode Genres\n",
    "for genre in unique_genres:\n",
    "    df[f\"Genre_{genre}\"] = df['genres'].str.contains(genre,regex =False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c309ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop original genre cols\n",
    "df  = df.drop(columns=['genres','genre_list','index'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82657d",
   "metadata": {},
   "source": [
    "### certification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a425c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking Certification values counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ebf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix extra space certs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix certification col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba94be",
   "metadata": {},
   "source": [
    "### Converting year to sep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefffc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split release date into 3 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop original feature\n",
    "df = df.drop(columns=['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ac1fe",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bead459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d644de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make x and y variables\n",
    "drop_for_model = ['title','imdb_id']\n",
    "\n",
    "y = df['revenue'].copy()\n",
    "X = df.drop(columns=['revenue',*drop_for_model]).copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)#, random_state=321)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b434dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make cat selector and using it to save list of column names\n",
    "cat_select = make_column_selector(dtype_include='object')\n",
    "cat_cols = cat_select(X_train)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select manually OHE cols for later\n",
    "bool_select = make_column_selector(dtype_include='bool')\n",
    "already_ohe_cols = bool_select(X_train)\n",
    "already_ohe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make num selector and using it to save list of column names\n",
    "num_select = make_column_selector(dtype_include='number')\n",
    "num_cols = num_select(X_train)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09062777",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert manual ohe to int\n",
    "X_train[already_ohe_cols] = X_train[already_ohe_cols].astype(int)\n",
    "X_test[already_ohe_cols] = X_test[already_ohe_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ffcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make pipelines\n",
    "cat_pipe = make_pipeline(SimpleImputer(strategy='constant',\n",
    "                                       fill_value='MISSING'),\n",
    "                         OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "num_pipe = make_pipeline(SimpleImputer(strategy='mean'),#StandardScaler()\n",
    "                        )\n",
    "\n",
    "preprocessor = make_column_transformer((cat_pipe,cat_cols),\n",
    "                                        (num_pipe, num_cols),\n",
    "                                       ('passthrough',already_ohe_cols))# remainder='passthrough')\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the col transformer\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "## Finding the categorical pipeline in our col transformer.\n",
    "preprocessor.named_transformers_['pipeline-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## B) Using list-slicing to find the encoder \n",
    "cat_features = preprocessor.named_transformers_['pipeline-1'][-1].get_feature_names_out(cat_cols)\n",
    "\n",
    "## Create the empty list\n",
    "final_features = [*cat_features,*num_cols,*already_ohe_cols]\n",
    "len(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62437d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking shape matches len final features\n",
    "preprocessor.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1742cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make X_train_tf \n",
    "X_train_tf = pd.DataFrame( preprocessor.transform(X_train), \n",
    "                          columns=final_features, index=X_train.index)\n",
    "X_train_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make X_test_tf \n",
    "\n",
    "X_test_tf = pd.DataFrame( preprocessor.transform(X_test), \n",
    "                         columns=final_features, index=X_test.index)\n",
    "X_test_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8203f",
   "metadata": {},
   "source": [
    "### Adding a Constant for Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import statsmodels correctly\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729495f6",
   "metadata": {},
   "source": [
    "> Tip: make sure that add_constant actually added a new column! You may need to change the parameter `has_constant` to \"add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e637869",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make final X_train_df and X_test_df with constants added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d1f5f",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c27c0",
   "metadata": {},
   "source": [
    "## Statsmodels OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0736a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## instantiate an OLS model WITH the training data.\n",
    "\n",
    "## Fit the model and view the summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676327d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get train data performance from skearn to confirm matches OLS\n",
    "\n",
    "\n",
    "## Get test data performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b994cb",
   "metadata": {},
   "source": [
    "# The Assumptions of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fba73",
   "metadata": {},
   "source": [
    "- The 4 Assumptions of a Linear Regression are:\n",
    "    - Linearity: That the input features have a linear relationship with the target.\n",
    "    - Independence of features (AKA Little-to-No Multicollinearity): That the features are not strongly related to other features.\n",
    "    - **Normality: The model's residuals are approximately normally distributed.**\n",
    "    - **Homoscedasticity: The model residuals have equal variance across all predictions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcb7bf",
   "metadata": {},
   "source": [
    "### QQ-Plot for Checking for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Q-QPlot\n",
    "\n",
    "# first calculate residuals \n",
    "\n",
    "\n",
    "## then use sm's qqplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e656b",
   "metadata": {},
   "source": [
    "### Residual Plot for Checking Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58277dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot scatterplot with y_hat_test vs resids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1aaf5",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350262af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ols(result,X_train_df, y_train):\n",
    "    \"\"\"Plots a Q-Q Plot and residual plot for a statsmodels OLS regression.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## save residuals from result\n",
    "    y_pred = result.predict(X_train_df)\n",
    "    resid = y_train - y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2,figsize=(12,5))\n",
    "    \n",
    "    ## Normality \n",
    "    sm.graphics.qqplot(resid,line='45',fit=True,ax=axes[0]);\n",
    "    \n",
    "    ## Homoscedasticity\n",
    "    ax = axes[1]\n",
    "    ax.scatter(y_pred, resid, edgecolor='white',lw=1)\n",
    "    ax.axhline(0,zorder=0)\n",
    "    ax.set(ylabel='Residuals',xlabel='Predicted Value');\n",
    "    plt.tight_layout()\n",
    "    \n",
    "evaluate_ols(result,X_train_df, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c32a9",
   "metadata": {},
   "source": [
    "> Next class: iterating on our model & interpreting coefficients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
